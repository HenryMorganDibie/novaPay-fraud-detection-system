# ğŸ’¸ NovaPay Fraud Detection System

### **End-to-End Machine Learning Prototype for Real-Time Fraud Scoring**

This repository contains a full machine learning workflow for detecting fraudulent money transfers on the NovaPay platform. The project demonstrates real-world data science practices across preparation, feature engineering, model benchmarking, deployment, and reporting.

The final model â€” **Tuned CatBoost Classifier** â€” powers a real-time risk-scoring demo app built with Streamlit.

---

### Demo Screenshot
![Streamlit Demo Screenshot](screenshot/demo_screenshot.jpg)

---

# ğŸ“ Project Structure

<pre lang="markdown">
fraud-detection-prototype/
â”‚
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ nova_pay_transactions.csv
â”‚   â”œâ”€â”€ cleaned_transactions.pkl
â”‚   â””â”€â”€ feature_engineered_transactions.pkl
â”‚
â”œâ”€â”€ demo/
â”‚   â”œâ”€â”€ app.py
â”‚   â””â”€â”€ __pycache__/
â”‚
â”œâ”€â”€ models/
â”‚   â”œâ”€â”€ preprocessor.joblib
â”‚   â”œâ”€â”€ CatBoost (Tuned)_fraud_model.joblib
â”‚   â”œâ”€â”€ catboost_fraud_model.joblib
â”‚   â”œâ”€â”€ lgb_fraud_model.joblib
â”‚   â””â”€â”€ xgb_fraud_model.joblib
â”‚
â”œâ”€â”€ notebooks/
â”‚   â”œâ”€â”€ 01_data_prep.ipynb
â”‚   â”œâ”€â”€ 02_eda_and_feature_engineering.ipynb
â”‚   â”œâ”€â”€ 03_multi_model_training.ipynb
â”‚   â””â”€â”€ catboost_info/
â”‚
â”œâ”€â”€ reports/
â”‚   â”œâ”€â”€ EDA_Report.md
â”‚   â”œâ”€â”€ Feature_Engineering_Report.md
â”‚   â””â”€â”€ Modeling_Report.md
â”‚
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ features.py
â”‚   â””â”€â”€ __pycache__/
â”‚
â”œâ”€â”€ .gitignore
â”œâ”€â”€ README.md
â””â”€â”€ requirements.txt
</pre>

---

# ğŸŒŸ Project Summary

This project builds a **production-ready fraud detection prototype** that handles:

* ğŸš¨ **Severe class imbalance** (â‰ˆ **1.93%** fraud)
* ğŸ§® **36 engineered features**
* ğŸ§  **Multiple gradient-boosted tree models**
* ğŸ” **Cost-sensitive learning**
* âš¡ **Fast real-time inference** with CatBoost
* ğŸ’» **Interactive Streamlit demo**

---

# ğŸ¯ Key Achievements

| Component               | Achievement                           | Technical Detail                            |
| ----------------------- | ------------------------------------- | ------------------------------------------- |
| **Data Challenge**      | Severe imbalance                      | Only **1.93%** (197/10,200) were fraudulent |
| **Feature Engineering** | Behavioural velocity features         | Rolling 3-day mean/count per customer       |
| **Modeling**            | Evaluated XGBoost, LightGBM, CatBoost | Tuned with cost-sensitive learning          |
| **Final Model**         | **Tuned CatBoost**                    | Best balance of Recall, Precision, AUC      |
| **Deployment**          | Streamlit scoring demo                | Recreates production-level inference        |

---

# ğŸ—ï¸ System Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Raw Data (CSV)              â”‚
â”‚ data/nova_pay_transactions  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
            â”‚
            â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Cleaning & Prep             â”‚
â”‚ notebooks/01_*              â”‚
â”‚ cleaned_transactions.pkl    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
            â”‚
            â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Feature Engineering          â”‚
â”‚ notebooks/02_*               â”‚
â”‚ feature_engineered_*.pkl     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
            â”‚
            â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Model Training & Selection   â”‚
â”‚ notebooks/03_*               â”‚
â”‚ CatBoost | XGB | LGB         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
            â”‚
            â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Export Best Model             â”‚
â”‚ models/catboost_fraud_model   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
            â”‚
            â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Real-Time Scoring Demo App   â”‚
â”‚ demo/app.py                  â”‚
â”‚ src/features.py              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

# ğŸ“Š Final Model Performance (CatBoost â€“ Tuned)

| Metric               | Score      | Interpretation                           |
| -------------------- | ---------- | ---------------------------------------- |
| **AUC-ROC**          | 0.7150     | Ability to separate fraud vs normal      |
| **AUC-PR**           | 0.0700     | Most important metric in imbalanced data |
| **Fraud Precision**  | 0.1515     | Of predicted fraud, 15% were true        |
| **Fraud Recall**     | 0.1282     | Fraction of actual fraud caught          |
| **F1-Score (Fraud)** | 0.1389     | Balance of precision & recall            |
| **Best Threshold**   | **0.6705** | Tuned to maximize Fraud F1               |

---

# ğŸ”¬ Data Preparation

### **1. Cleaning**

* Converted timestamps â†’ datetime
* Converted channel, kyc_tier â†’ categorical dtype
* Missing value indicators:

  * `ip_missing`, `kyc_missing`, `device_trust_missing`

### **2. Domain-Aware Imputation**

* `amount_usd = amount_src Ã— exchange_rate`
  â†’ prevents numeric distortion

### **3. Feature Engineering**

Key feature groups:

#### **Temporal**

* `txn_hour`
* `is_weekend`
* `txn_day_of_month`

#### **Risk Features**

* `ip_risk_score`
* `risk_score_internal`
* `corridor_risk`

#### **Behavioral Velocity**

* `txn_count_prev_3d`
* `mean_amount_prev_3d`

Velocity features were critical for detecting **Account Takeover (ATO)** behavior.

---

# ğŸ¤– Modeling & Benchmarking

Three models were compared:

| Model                | AUC-ROC    | AUC-PR | Precision | Recall | F1   |
| -------------------- | ---------- | ------ | --------- | ------ | ---- |
| **XGBoost**          | 0.7148     | 0.0848 | 0.12      | 0.23   | 0.16 |
| **LightGBM**         | 0.6814     | 0.0723 | 0.12      | 0.13   | 0.12 |
| **CatBoost (Tuned)** | **0.7150** | 0.0700 | 0.15      | 0.13   | 0.14 |

### **Why CatBoost Was Selected**

* Best overall trade-off between FP & FN
* Handles categorical features natively
* No need for one-hot encoding â†’ easier deployment
* More stable on noisy financial data

---

# âš¡ Real-Time Inference Workflow

```
User Input â†’ Feature Builder (src/features.py) â†’ Load CatBoost Model â†’
Predict Probability â†’ Apply Threshold â†’ Output Fraud / Legit + Score
```

### **Steps Inside `app.py`:**

1. User enters transaction details
2. Build raw feature dict
3. `features.py` generates **36 engineered features**
4. Model loads from `models/catboost_fraud_model.joblib`
5. Prediction returned instantly
6. UI displays:

   * Fraud probability
   * Decision (Fraud / Legitimate)
   * Key contributing factors (future work)

---

# ğŸš€ How to Run the Demo App

### **1. Clone the Repo**

```bash
git clone https://github.com/HenryMorganDibie/novaPay-fraud-detection-system.git
cd novaPay-fraud-detection-system
```

### **2. Create Environment**

```bash
python -m venv .venv
.venv/Scripts/activate   # Windows
# or: source .venv/bin/activate  # macOS/Linux
```

### **3. Install Requirements**

```bash
pip install -r requirements.txt
```

### **4. Run Streamlit App**

```bash
streamlit run demo/app.py
```

The UI opens in your browser and allows you to score transactions in real time.

---

# ğŸ”§ Tools & Technologies

* **Python 3.10+**
* Pandas, NumPy
* CatBoost, XGBoost, LightGBM
* Scikit-Learn
* Joblib
* Streamlit
* Jupyter Notebooks
* Seaborn, Matplotlib

---

# ğŸ“¦ Model Artifacts (models/ Directory)

| File                                  | Description                          |
| ------------------------------------- | ------------------------------------ |
| `catboost_fraud_model.joblib`         | **Final deployed model**             |
| `CatBoost (Tuned)_fraud_model.joblib` | Tuned training version               |
| `xgb_fraud_model.joblib`              | Benchmark model                      |
| `lgb_fraud_model.joblib`              | Benchmark model                      |
| `preprocessor.joblib`                 | Encoding/transform logic (if needed) |

---

# ğŸ“ˆ Monitoring & Drift Strategy

Planned production monitoring:

### **1. Prediction Drift**

* Monitor decline in recall
* Monitor spike in false positives

### **2. Feature Drift**

* Track distribution changes in:

  * Amount
  * Velocity features
  * Risk signals

### **3. Label Delay**

* Fraud labels often arrive weeks later
* Pipeline supports delayed supervised updates

### **4. Retraining**

* Scheduled retraining every 30 days
* OR triggered when drift exceeds threshold

---

# ğŸ§­ Future Improvements

* Add FastAPI for real-time API scoring
* Add SHAP explainability
* Use PostgreSQL or MongoDB for customer history lookups
* Expand rolling windows (1, 7, 30 days)
* Implement Kafka streaming pipeline
* Build ensemble fraud scoring engine
* Add real-time alerting dashboard

---

# ğŸ¤ Contributing

Pull requests are welcome.

Steps:

```bash
git checkout -b feature/my-feature
# make changes
git push origin feature/my-feature
```

Please follow PEP8 and include documentation updates.

---

# ğŸ“œ License

Released under the **MIT License**.

---
